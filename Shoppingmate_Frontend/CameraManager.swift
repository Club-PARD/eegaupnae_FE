//
//  CameraManager.swift
//  Shoppingmate_Frontend
//
//  Created by Jinsoo Park on 12/26/25.
//
import AVFoundation
import Vision
import UIKit
import SwiftUI
import Combine

//@MainActor
final class CameraManager: NSObject, ObservableObject {
    
    // SwiftUIì—ì„œ ê´€ì°°í•  ìƒíƒœ
    @Published var recognizedText: String = ""
    @Published var isProcessing = false
    @Published var croppedROIImage: UIImage? = nil // ROIë¡œ ì˜ë¦° ì´ë¯¸ì§€ ì €ì¥ ë³€ìˆ˜
    
    // ì¹´ë©”ë¼ ì„¸ì…˜
    let session = AVCaptureSession()
    private let photoOutput = AVCapturePhotoOutput()
    private let sessionQueue = DispatchQueue(label: "camera.session.queue") // ì„¸ì…˜ ì œì–´ ì „ìš© ë°±ê·¸ë¼ìš´ë“œ ë§Œë“¤ê¸°
    
    // í”„ë¦¬ë·° ë ˆì´ì–´ (ì¢Œí‘œ ë³€í™˜ìš©)
    // - SwiftUI CameraPreview(UIViewRepresentable)ì—ì„œ ìƒì„±ëœ previewLayerë¥¼ ì—¬ê¸°ë¡œ ì£¼ì…í•´ì•¼ í•¨
    var previewLayer: AVCaptureVideoPreviewLayer?
    
    // SwiftUIì—ì„œ ê³„ì‚°í•œ ROI (previewLayer ì¢Œí‘œê³„)
    // - ROIOverlayì—ì„œ ê³„ì‚°í•œ CGRectë¥¼ updateROIRectë¡œ ê³„ì† ë„£ì–´ì¤Œ
    fileprivate var roiLayerRect: CGRect = .zero
    
    // MARK: - Session ì„¤ì •
    func startSession() {
        sessionQueue.async {
            if self.session.isRunning { return }
            
            self.session.beginConfiguration()
            self.session.sessionPreset = .photo
            
            guard
                let device = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                     for: .video,
                                                     position: .back),
                let input = try? AVCaptureDeviceInput(device: device),
                self.session.canAddInput(input)
            else {
                print("âŒ Camera input error")
                return
            }
            
            self.session.addInput(input)
            
            guard self.session.canAddOutput(self.photoOutput) else {
                print("âŒ Photo output error")
                return
            }
            
            self.session.addOutput(self.photoOutput)
            
            self.session.commitConfiguration()
            self.session.startRunning() // âœ… ë°±ê·¸ë¼ìš´ë“œ
        }
    }
    
    func stopSession() {
        sessionQueue.async {
            if self.session.isRunning {
                self.session.stopRunning()
            }
        }
    }
    
    // SwiftUI ROI ì „ë‹¬
    @MainActor
    func updateROIRect(_ rect: CGRect) {
        roiLayerRect = rect
    }
    
    // MARK: - ì‚¬ì§„ ì´¬ì˜
    func capturePhoto() {
        sessionQueue.async {
            guard self.session.isRunning else { return }
            
            let settings = AVCapturePhotoSettings()
            
            if let conn = self.photoOutput.connection(with: .video) {
                       if conn.isVideoRotationAngleSupported(0) {
                           conn.videoRotationAngle = 0   // portrait
                       }
                   }
            
            Task { @MainActor in
                        self.isProcessing = true

                        if let layer = self.previewLayer {
                            let b = layer.bounds
                            let rect = CGRect(
                                x: b.width * 0.1,
                                y: b.height * 0.4,
                                width: b.width * 0.8,
                                height: b.height * 0.2
                            )
                            self.roiLayerRect = rect
                            print("ğŸ“Œ forced roiLayerRect:", rect)
                            print("ğŸ“Œ layer.bounds:", b)
                        } else {
                            print("âŒ previewLayer is nil at capture")
                        }
                    }
            
            self.photoOutput.capturePhoto(with: settings, delegate: self)
        }
    }
}
        
        // MARK: - AVCapturePhotoCaptureDelegate
        extension CameraManager: AVCapturePhotoCaptureDelegate {
            
            /// DelegateëŠ” ë©”ì¸ ì•¡í„° ë°–ì—ì„œ í˜¸ì¶œë  ìˆ˜ ìˆì–´ì„œ nonisolatedë¡œ ë‘ 
            nonisolated func photoOutput(_ output: AVCapturePhotoOutput,
                                         didFinishProcessingPhoto photo: AVCapturePhoto,
                                         error: Error?) {
                
                if let error {
                    print("âŒ Capture error:", error)
                    return
                }
                
                guard let data = photo.fileDataRepresentation() else { return }
                
                // âœ… MainActorì—ì„œ UIKit ì‘ì—… ì²˜ë¦¬
                Task { @MainActor in
                    guard let rawImage = UIImage(data: data) else {
                        self.isProcessing = false
                        return
                    }
                    
                    // âœ… ì—¬ê¸°ì„œ ì •ê·œí™” (MainActor OK)
                    let image = rawImage.normalizedUp()               // orientation ë©”íƒ€ ì •ë¦¬

                    
                    guard let cgImage = image.cgImage else {
                        self.isProcessing = false
                        return
                    }
                    
                    let layer = self.previewLayer
                    let roi = self.roiLayerRect
                    let uiOrientation = rawImage.imageOrientation
                    let scale = rawImage.scale
                    
                    guard let layer else {
                        self.isProcessing = false
                        return
                    }
                    

                    Task.detached { [layer, roi] in
                        let cropped = CameraManager.cropToROI(
                            cgImage: cgImage,
                            previewLayer: layer,
                            roiLayerRect: roi
                        )
                        
                        let text = CameraManager.performOCR(
                            cgImage: cgImage,
                            previewLayer: layer,
                            roiLayerRect: roi
                        )
                        
                        await MainActor.run {
                            self.croppedROIImage = cropped
                            self.recognizedText = text
                            self.isProcessing = false
                        }
                    }
                }
            }
        }
        
        // MARK: - OCR (Vision)
        extension CameraManager {
            
            // MainActorì™€ ë¶„ë¦¬ëœ "ìˆœìˆ˜ OCR í•¨ìˆ˜"
            // - background(Task.detached)ì—ì„œ ì•ˆì „í•˜ê²Œ í˜¸ì¶œ ê°€ëŠ¥
            nonisolated
            static func performOCR(
                cgImage: CGImage,
                previewLayer: AVCaptureVideoPreviewLayer,
                roiLayerRect: CGRect
            ) -> String {
                
                // 1) SwiftUI ROI(layer ì¢Œí‘œ) -> ì¹´ë©”ë¼ ì •ê·œí™” ì¢Œí‘œ(0~1, origin=top-left)
                let metadataROI =
                previewLayer.metadataOutputRectConverted(fromLayerRect: roiLayerRect)
                
                // 2) Vision ROIëŠ” originì´ bottom-leftë¼ì„œ yë¥¼ ë’¤ì§‘ì–´ì•¼ í•¨
                let visionROI = CGRect(
                    x: metadataROI.origin.x,
                    y: 1 - metadataROI.origin.y - metadataROI.height,
                    width: metadataROI.width,
                    height: metadataROI.height
                )
                
                let request = VNRecognizeTextRequest()
                request.recognitionLevel = .accurate
                request.regionOfInterest = visionROI
                request.usesLanguageCorrection = true
                request.recognitionLanguages = ["ko-KR", "en-US"]
                request.automaticallyDetectsLanguage = false
                
                
                // âš ï¸ ê¸°ê¸° ë°©í–¥ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ (ì¼ë‹¨ portrait ê¸°ì¤€ìœ¼ë¡œ .right)
                let handler = VNImageRequestHandler(
                    cgImage: cgImage,
                    orientation: .up,
                    options: [:]
                )
                
                do {
                    try handler.perform([request])
                } catch {
                    return "âŒ Vision error: \(error.localizedDescription)"
                }
                
                let results = request.results as? [VNRecognizedTextObservation] ?? []
                
                return results
                    .compactMap { $0.topCandidates(1).first?.string }
                    .joined(separator: "\n")
            }
            
            
            nonisolated
            static func cropToROI( //ROI í¬ë¡­ í•©ìˆ˜
                cgImage: CGImage,
                previewLayer: AVCaptureVideoPreviewLayer,
                roiLayerRect: CGRect
            ) -> UIImage? {
                
                let metadataROI = previewLayer.metadataOutputRectConverted(fromLayerRect: roiLayerRect)
                print("roiLayerRect:", roiLayerRect)
                print("previewLayer bounds:", previewLayer.bounds)
                print("metadataROI:", metadataROI)
                
                let W = CGFloat(cgImage.width)
                let H = CGFloat(cgImage.height)
                
                var rect = CGRect(
                    x: metadataROI.origin.x * W,
                    y: (1 - metadataROI.origin.y - metadataROI.size.height) * H,
                    width: metadataROI.size.width * W,
                    height: metadataROI.size.height * H
                ).integral
                
                rect = rect.intersection(CGRect(x: 0, y: 0, width: W, height: H))
                guard !rect.isNull, rect.width > 1, rect.height > 1 else { return nil }
                
                guard let croppedCG = cgImage.cropping(to: rect) else { return nil }
                return UIImage(cgImage: croppedCG)
            }
            
}





extension UIImage {
    // imageOrientation(ë©”íƒ€) ë¥¼ í”½ì…€ì— ë°˜ì˜í•´ì„œ ì‹¤ì œë¡œ .upì¸ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ì–´ì¤Œ
    func normalizedUp() -> UIImage {
        if imageOrientation == .up { return self }
        
        let format = UIGraphicsImageRendererFormat.default()
        format.scale = 1   // ì›ë³¸ í”½ì…€ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬(ì¶”ì²œ)
        
        return UIGraphicsImageRenderer(size: size, format: format).image { _ in
            draw(in: CGRect(origin: .zero, size: size))
        }
    }
    
}
