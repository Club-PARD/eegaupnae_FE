//
//  CameraManager.swift
//  Shoppingmate_Frontend
//
//  Created by Jinsoo Park on 12/26/25.

import AVFoundation
import Vision
import UIKit
import Combine//@Published (ObservableObjectìš©)

//@MainActor
final class CameraManager: NSObject, ObservableObject {
    
    private let uploadService = UploadService()
    private var isConfigured = false //ì¹´ë©”ë¼ ìµœì´ˆ ì„¸íŒ… ì™„ë£Œ ì—¬ë¶€
    
    // SwiftUIì—ì„œ ê´€ì°°í•  ìƒíƒœ
    @Published var recognizedText: String = "" //OCR ê²°ê³¼ ì¶œë ¥(ìš©)
    @Published var isProcessing = false //OCR ë¡œë”© ì¤‘
    @Published var croppedROIImage: UIImage? = nil // ROIë¡œ ì˜ë¦° ì´ë¯¸ì§€ ì €ì¥ ë³€ìˆ˜ (ì°ìœ¼ë©´ ì—…ë°ì´íŠ¸)
    
    @Published var capturedROIImages: [UIImage] = []   // ì‚¬ì§„ ì—¬ëŸ¬ ì¥ ëˆ„ì  ì €ì¥
//    @Published var capturedTexts: [String] = []        // OCR ëˆ„ì 
    @Published var OCRFilters: [OCRFilter] = []        // OCR í•„ìš”í•œ ì •ë³´ë§Œ í•„í„°
    
    // ì¹´ë©”ë¼ ì„¸ì…˜
    let session = AVCaptureSession()
    private let photoOutput = AVCapturePhotoOutput()//photoOutput: ì‹¤ì œ ì‚¬ì§„ ì´¬ì˜ ë‹´ë‹¹
    private let sessionQueue = DispatchQueue(label: "camera.session.queue") // ì„¸ì…˜ ì œì–´ ì „ìš© ë°±ê·¸ë¼ìš´ë“œ ë§Œë“¤ê¸°
    
    var previewLayer: AVCaptureVideoPreviewLayer? // í”„ë¦¬ë·° ë ˆì´ì–´
    
    // ROIOverlayì—ì„œ ê³„ì‚°í•œ ROI (previewLayer ì¢Œí‘œê³„)
    fileprivate var roiLayerRect: CGRect = .zero
    
    //ë””ë²„ê·¸
    private func logROIContext(_ tag: String) {
        print("\n===== [ROI DEBUG] \(tag) =====")
        if let layer = previewLayer {
            print("layer.bounds:", layer.bounds)
            print("layer.videoGravity:", layer.videoGravity.rawValue)
            print("layer.contentsScale:", layer.contentsScale)
        } else {
            print("layer: nil")
        }
        print("roiLayerRect:", roiLayerRect)
        print("=============================\n")
    }
    
    // MARK: - Session ì„¤ì •
        func configureSession() { // ì¹´ë©”ë¼ ì„¸ì…˜ ìµœì´ˆ ì„¸íŒ… 1íšŒ í›„ ìœ ì§€
        guard !isConfigured else { return } //ì„¸íŒ…ì´ ë˜ì–´ìˆì„ ì‹œ return

        session.beginConfiguration() // ì¹´ë©”ë¼ ì„¤ì • ì‹œì‘
        session.sessionPreset = .photo //ì‚¬ì§„ ì´¬ì˜ ìµœì í™” í”„ë¦¬ì…‹
            
        // ì¹´ë©”ë¼ ë””ë°”ì´ìŠ¤
        guard
            // í›„ë©´ ì¹´ë©”ë¼ ê°€ì ¸ì˜¤ê¸°
            let device = AVCaptureDevice.default(.builtInWideAngleCamera, //í›„ë©´ ì¹´ë©”ë¼ ì‚¬ìš© ë””ë²„ê·¸
                                                 for: .video,
                                                 position: .back),
            let input = try? AVCaptureDeviceInput(device: device),
            // ì¹´ë©”ë¼ë¥¼ ì„¸ì…˜ ì…ë ¥ìœ¼ë¡œ ì—°ê²°
            session.canAddInput(input)
        else {
            print("âŒ Camera input error")
            session.commitConfiguration() //ì„¤ì • ì™„ë£Œ
            return
        }
        session.addInput(input)

        guard session.canAddOutput(photoOutput) else { //ì‚¬ì§„ ì°ê¸° ì „ìš© ì¶œë ¥
            print("âŒ Photo output error")
            session.commitConfiguration()
            return
        }
        session.addOutput(photoOutput) //ì¹´ë©”ë¼&ì‚¬ì§„ ì—°ê²° íŒŒì´í”„

        session.commitConfiguration() //ì„¤ì • ì™„ë£Œ
        isConfigured = true
    }
    
    func startSession() { // ì¹´ë©”ë¼ ì¼œì§
        sessionQueue.async { //ì„¸ì…˜ ì œì–´ìš© ì „ìš© í ë°±ê·¸ë¼ìš´ë“œì—ì„œ
            self.configureSession()
            guard !self.session.isRunning else { return }
            self.session.startRunning()
        }
    }
    
    func stopSession() {
        sessionQueue.async {
            if self.session.isRunning {
                self.session.stopRunning()
            }
        }
    }
    
    // SwiftUI ROI ì „ë‹¬
    @MainActor
    func updateROIRect(_ rect: CGRect) {
        roiLayerRect = rect
        if roiLayerRect != .zero, previewLayer != nil { //ë¡œê·¸ ì°ì„ì§€ íŒë‹¨ (ì¢Œí‘œ ë””ë²„ê¹…)
            logROIContext("updateROIRect")
        }
    }
    
    // MARK: - ì‚¬ì§„ ì´¬ì˜
    func capturePhoto() {
        sessionQueue.async { //ì´¬ì˜ ì „ìš© í
            guard self.session.isRunning else { return }
            
            let settings = AVCapturePhotoSettings() //ê¸°ë³¸ ì¹´ë©”ë¼ ì„¸íŒ…
            
            if let conn = self.photoOutput.connection(with: .video) {
                if conn.isVideoOrientationSupported {
                    conn.videoOrientation = .portrait
                } else if conn.isVideoRotationAngleSupported(90) {
                    conn.videoRotationAngle = 90
                }
            }
            
            Task { @MainActor in //ì´¬ì˜
                self.isProcessing = true //ì´¬ì˜ + OCR ì²˜ë¦¬
                
                // ì´¬ì˜ ìˆœê°„ì— previewLayer.bounds ê¸°ì¤€ìœ¼ë¡œ ROIë¥¼ ê°•ì œ ê³„ì‚°
                if let layer = self.previewLayer {
                    let b = layer.bounds
                    let rect = CGRect(
                        x: b.width * 0.1,
                        y: b.height * 0.4,
                        width: b.width * 0.8,
                        height: b.height * 0.2
                    )
                    self.roiLayerRect = rect
                    print("ğŸ“Œ forced roiLayerRect:", rect)
                } else {
                    print("âŒ previewLayer is nil at capture")
                }
                
                // ë¡œê·¸ ì°ê¸°
                self.logROIContext("capturePhoto: before capture")
                
            }
            
            //ì‹¤ì œ ì´¬ì˜ í›„ delegateë¡œ ê²°ê³¼ ë°›ê¸°
            self.photoOutput.capturePhoto(with: settings, delegate: self)
        }
    }
} //final class
    
    
    // MARK: - AVCapturePhotoCaptureDelegate
    extension CameraManager: AVCapturePhotoCaptureDelegate { //ì´¬ì˜ ê²°ê³¼ delegateë¡œ ë°›ì•„ì˜¤ê¸°
        
        /// DelegateëŠ” ë©”ì¸ ì•¡í„° ë°–ì—ì„œ í˜¸ì¶œë  ìˆ˜ ìˆì–´ì„œ nonisolatedë¡œ ë‘ 
        nonisolated func photoOutput(_ output: AVCapturePhotoOutput,
                                     didFinishProcessingPhoto photo: AVCapturePhoto,
                                     error: Error?) {
            
            if let error {
                print("âŒ Capture error:", error)
                return
            }
            
            guard let data = photo.fileDataRepresentation() else { return } //ì´ë¯¸ì§€ ë°ì´í„°ë¡œ ë³€í™˜
            
            // MainActorì—ì„œ UIKit ì‘ì—… ì²˜ë¦¬
            Task { @MainActor in
                guard let rawImage = UIImage(data: data) else { //ì´ë¯¸ì§€ ë°ì´í„°
                    self.isProcessing = false
                    return
                }
                
                // ì—¬ê¸°ì„œ ì •ê·œí™”
                let image = rawImage.normalizedUp() // ì´ë¯¸ì§€ ë‹¤ì‹œ ê·¸ë ¤ì„œ .up ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                
                guard let cgImage = image.cgImage else { //í”½ì…€ ë°°ì—´ ì´ë¯¸ì§€ (width x height)
                    self.isProcessing = false
                    return
                }
                
                let layer = self.previewLayer
                let roi = self.roiLayerRect //ì´¬ì˜ ìˆœê°„ ROI ê³ ì •
                
                guard let layer else {
                    self.isProcessing = false
                    return
                }
                
                Task.detached { [layer, roi] in
                    let cropped = CameraManager.cropToROI( //ROI ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ í¬ë¡­
                        cgImage: cgImage,
                        previewLayer: layer,
                        roiLayerRect: roi
                    )
                    
                    let text = CameraManager.performOCR( //OCR ìˆ˜í–‰
                        cgImage: cgImage,
                        previewLayer: layer,
                        roiLayerRect: roi
                    )
                    
                    await MainActor.run {
                        //ROI ë°•ìŠ¤ë‘ ê°™ì€ ì‚¬ì´ì¦ˆë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                        let scale = layer.contentsScale   // ë³´í†µ 2.0 / 3.0
                        let targetSize = CGSize(
                            width: roi.width * scale,
                            height: roi.height * scale
                        )
                        
                        if let cropped {
                            let resized = cropped.resized(to: targetSize) //ë¦¬ì‚¬ì´ì¦ˆ ì ìš©
                            self.croppedROIImage = resized                // ë§ˆì§€ë§‰ 1ì¥
                            self.capturedROIImages.append(resized)        // ì´ë¯¸ì§€ ëˆ„ì 
                        }
                        
                        self.recognizedText = text                    // ë§ˆì§€ë§‰ OCR
                        
                        if let item = Self.parseItem(from: text) {
                            self.OCRFilters.append(item)              // íŒŒì‹±í•œ OCR ê²°ê³¼ ëˆ„ì 
                        }
                        
//                        if !text.isEmpty {
//                            self.capturedTexts.append(text)           // OCR ëˆ„ì 
//                        }
                        self.isProcessing = false
                    }
                }
            }
        }
    }
    
   
    
    // MARK: - OCR (Vision)
    extension CameraManager { //MainActorì™€ ë¶„ë¦¬ëœ OCR í•¨ìˆ˜ (Task.detachedì—ì„œ ì•ˆì „í•˜ê²Œ í˜¸ì¶œ ê°€ëŠ¥)
        nonisolated
        static func videoRectInLayer(bounds: CGRect, imageSize: CGSize) -> CGRect {
            let layerW = bounds.width
            let layerH = bounds.height
            
            let imageAspect = imageSize.width / imageSize.height
            let layerAspect = layerW / layerH
            
            if imageAspect > layerAspect {
                // ì˜ìƒì´ ë” ë„“ìŒ â†’ ë†’ì´ì— ë§ì¶° ì±„ìš°ë©´ ì¢Œìš°ê°€ ì˜ë¦¼
                let videoH = layerH
                let videoW = videoH * imageAspect
                let x = (layerW - videoW) / 2
                return CGRect(x: x, y: 0, width: videoW, height: videoH)
            } else {
                // ì˜ìƒì´ ë” ê¸¸ì­‰í•¨ â†’ ë„ˆë¹„ì— ë§ì¶° ì±„ìš°ë©´ ìƒí•˜ê°€ ì˜ë¦¼
                let videoW = layerW
                let videoH = videoW / imageAspect
                let y = (layerH - videoH) / 2
                return CGRect(x: 0, y: y, width: videoW, height: videoH)
            }
        }
        
        nonisolated
        static func normalizedRectFromLayerRect(
            _ layerRect: CGRect,
            layerBounds: CGRect,
            imageSize: CGSize
        ) -> CGRect {
            let videoRect = videoRectInLayer(bounds: layerBounds, imageSize: imageSize)
            
            let nx = (layerRect.minX - videoRect.minX) / videoRect.width
            let ny = (layerRect.minY - videoRect.minY) / videoRect.height
            let nw = layerRect.width / videoRect.width
            let nh = layerRect.height / videoRect.height
            
            func clamp(_ v: CGFloat) -> CGFloat { min(max(v, 0), 1) }
            
            let x = clamp(nx)
            let y = clamp(ny)
            
            // nx/nyê°€ ìŒìˆ˜ë©´ width/heightë„ ê°™ì´ ì¤„ì—¬ì„œ clampë˜ê²Œ ë³´ì •
            let w = clamp(nw + min(0, nx))
            let h = clamp(nh + min(0, ny))
            
            return CGRect(x: x, y: y, width: w, height: h)
        }
        
        nonisolated
        static func performOCR( // ROI ì˜ì—­ë§Œ í…ìŠ¤íŠ¸ ì¸ì‹í•´ì„œ String ë°˜í™˜
            cgImage: CGImage, //ì›ë³¸ í”½ì…€ ì´ë¯¸ì§€
            previewLayer: AVCaptureVideoPreviewLayer, //í”„ë¦¬ë·° ë ˆì´ì–´
            roiLayerRect: CGRect //ROI ì¢Œí‘œê³„
        ) -> String {
            
            let imageSize = CGSize(width: cgImage.width, height: cgImage.height)
            
            // ì§ì ‘ ê³„ì‚°í•œ ì¹´ë©”ë¼ ì •ê·œí™” ì¢Œí‘œ ROI (top-left)
            let normROI = normalizedRectFromLayerRect(
                roiLayerRect,
                layerBounds: previewLayer.bounds,
                imageSize: imageSize
            )
            
            // Visionì€ originì´ bottom-leftë¼ y ë’¤ì§‘ê¸°
            let visionROI = CGRect(
                x: normROI.origin.x,
                y: 1 - normROI.origin.y - normROI.height,
                width: normROI.width,
                height: normROI.height
            )
            
            let request = VNRecognizeTextRequest() //í…ìŠ¤íŠ¸ ì¸ì‹ ìš”ì²­ ê°ì²´
            request.recognitionLevel = .accurate //ì¸ì‹ ì •í™•ë„
            request.regionOfInterest = visionROI //ROI ìƒìë§Œ
            request.usesLanguageCorrection = true //í›„ë³´ì •
            request.recognitionLanguages = ["ko-KR", "en-US"] //ì–¸ì–´ ì„¤ì •
            request.automaticallyDetectsLanguage = false //ìë™ì–¸ì–´ê°ì§€ ì˜¤í”„
            
            
            // Vision ìš”ì²­ ì‹¤í–‰ê¸°
            let handler = VNImageRequestHandler(
                cgImage: cgImage,
                orientation: .up,
                options: [:]
            )
            
            //OCR ì‹¤í–‰
            do {
                try handler.perform([request])
            } catch {
                return "âŒ Vision error: \(error.localizedDescription)"
            }
            
            //ê²°ê³¼ êº¼ë‚´ê¸°
            let results = request.results as? [VNRecognizedTextObservation] ?? []
            
            //ê²°ê³¼ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
            return results
                .compactMap { $0.topCandidates(1).first?.string }
                .joined(separator: "\n")
            
        }
        
        nonisolated
        static func cropToROI( //ROI ì˜ì—­ë§Œ ì˜ë¼ì„œ UIImage ë°˜í™˜
            cgImage: CGImage,
            previewLayer: AVCaptureVideoPreviewLayer,
            roiLayerRect: CGRect
        ) -> UIImage? {
            
            //ì›ë³¸ ì´ë¯¸ì§€ í”½ì…€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            let W = CGFloat(cgImage.width)
            let H = CGFloat(cgImage.height)
            let imageSize = CGSize(width: W, height: H)
            
            // ì§ì ‘ ê³„ì‚°í•œ ì •ê·œí™” ROI (top-left)
            let normROI = normalizedRectFromLayerRect(
                roiLayerRect,
                layerBounds: previewLayer.bounds,
                imageSize: imageSize
            )
            
            // í”½ì…€ rectë¡œ ë³€í™˜ (y ë’¤ì§‘ê¸°)
            var rect = CGRect(
                x: normROI.origin.x * W,
                y: (1 - normROI.origin.y - normROI.height) * H,
                width: normROI.width * W,
                height: normROI.height * H
            ).integral
            
            print("normROI:", normROI)
            print("pixelRect:", rect)
            print("layer.bounds:", previewLayer.bounds)
            print("cgImage:", cgImage.width, "x", cgImage.height)
            
            //ì´ë¯¸ì§€ ê²½ê³„ ë°–ìœ¼ë¡œ ë‚˜ê°„ê±° ì˜ë¼ë‚´ê¸°
            rect = rect.intersection(CGRect(x: 0, y: 0, width: W, height: H))
            guard !rect.isNull, rect.width > 1, rect.height > 1 else { return nil }
            
            //í¬ë¡­ ìˆ˜í–‰
            guard let croppedCG = cgImage.cropping(to: rect) else { return nil }
            //UIImageë¡œ ë°˜í™˜
            return UIImage(cgImage: croppedCG)
            
        }
        
        
        
        static func parseItem(from text: String) -> OCRFilter? { //OCR íŒŒì‹± í•¨ìˆ˜
            //ê³µë°± ì œê±°
            let lines = text
                .components(separatedBy: .newlines)
                .map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
                .filter { !$0.isEmpty }

            // ê°€ê²© ì¶”ì¶œ: ì¤„ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ Intë¡œ ë³€í™˜
            var bestPrice: Int? = nil
            for line in lines.reversed() { //ì•„ë«ì¤„ë¶€í„° ê²€ì‚¬
                let digits = line.filter { $0.isNumber } // ìˆ«ìë§Œ ë½‘ê¸° (ì½¤ë§ˆ/ì›/â‚© ìë™ ì œê±°)
                if digits.count >= 4, let v = Int(digits) {   // 4ìë¦¬ ì´ìƒë§Œ ê°€ê²©ìœ¼ë¡œ ê°€ì •
                    bestPrice = v
                    break
                }
            }
            guard let price = bestPrice else { return nil } //ê°€ê²© ì°¾ê¸° ì‹¤íŒ¨í•˜ë©´ ë¦¬í„´

            // ìƒí’ˆëª… ì¶”ì¶œ: ìˆ«ìê°€ ë„ˆë¬´ ë§ì€ ì¤„ì€ ì œì™¸í•˜ê³  ê°€ì¥ ê¸´ ì¤„ì„ ì´ë¦„ìœ¼ë¡œ
            let nameCandidates = lines.filter { line in
                let digitCount = line.filter { $0.isNumber }.count // ì¤„ ì•ˆì— ìˆ«ì ê°œìˆ˜ ì¹´ìš´íŠ¸
                return digitCount <= max(2, line.count / 5) //ìˆ«ì ì¤„ ê¸¸ì´ì˜ 20%ë§Œ, ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ í—ˆìš©
            }
            
            //í›„ë³´ ì¤‘ ê°€ì¥ ê¸´ ì¤„ì„ ì±„íƒ
            let name = (nameCandidates.max(by: { $0.count < $1.count }) ?? lines.first ?? "").trimmingCharacters(in: .whitespaces)

            guard !name.isEmpty else { return nil }
            return OCRFilter(name: name, price: price, rawText: text)
        }

        
    }
    
    extension UIImage {
        // imageOrientation(ë©”íƒ€)ë¥¼ í”½ì…€ì— ë°˜ì˜í•´ì„œ ì‹¤ì œë¡œ .upì¸ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ì–´ì¤Œ
        func normalizedUp() -> UIImage {
            if imageOrientation == .up { return self } //ë°©í–¥ .upìœ¼ë¡œ
            
            let format = UIGraphicsImageRendererFormat.default()
            format.scale = 1   // í•´ìƒë„ë¥¼ ì›ë³¸ í”½ì…€ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬(1pt = 1px)
            
            return UIGraphicsImageRenderer(size: size, format: format).image { _ in
                draw(in: CGRect(origin: .zero, size: size)) //í”½ì…€ ìì²´ë¡œ íšŒì „ëœ ìƒíƒœë¡œ ë‹¤ì‹œ ê·¸ë¦¬ê¸°
            }
        }
        func resized(to targetSize: CGSize) -> UIImage { //ì‚¬ì§„ ë¦¬ì‚¬ì´ì¦ˆ
            let renderer = UIGraphicsImageRenderer(size: targetSize)
            return renderer.image { _ in
                self.draw(in: CGRect(origin: .zero, size: targetSize))
            }
        }
    }
